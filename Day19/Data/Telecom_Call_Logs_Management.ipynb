{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7bbac39",
   "metadata": {},
   "source": [
    "# Telecom Domain: Call Logs Management with Delta Lake Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef045b",
   "metadata": {},
   "source": [
    "In this notebook, we will manage telecom call logs using Delta Lake operations such as Insert Overwrite, Append Rows, Merge Updates, and Copy Into."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930601c0",
   "metadata": {},
   "source": [
    "### Step 1: Create and Replace Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create and replace a table with call logs using CTAS\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE telecom.call_logs AS\n",
    "SELECT * FROM csv.`/mnt/data/telecom_call_logs.csv`;\n",
    "\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611d0e3",
   "metadata": {},
   "source": [
    "### Step 2: Insert Overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd183af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insert overwrite with call logs\n",
    "spark.sql(\"\"\"\n",
    "INSERT OVERWRITE telecom.call_logs\n",
    "SELECT * FROM csv.`/mnt/data/telecom_call_logs.csv`;\n",
    "\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c00664",
   "metadata": {},
   "source": [
    "### Step 3: Append Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1323e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append new rows to the telecom call logs\n",
    "spark.sql(\"\"\"\n",
    "INSERT INTO telecom.call_logs\n",
    "SELECT * FROM csv.`/mnt/data/telecom_call_logs_incremental.csv`;\n",
    "\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9bc22",
   "metadata": {},
   "source": [
    "### Step 4: Merge Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge updates and new records into the telecom call logs\n",
    "# Create a temporary view for the updates\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW call_logs_updates AS\n",
    "SELECT * FROM csv.`/mnt/data/telecom_call_logs_incremental.csv`;\n",
    "\"\"\")\n",
    "    \n",
    "# Perform a merge operation\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO telecom.call_logs a\n",
    "USING call_logs_updates b\n",
    "ON a.Call_ID = b.Call_ID\n",
    "WHEN MATCHED THEN UPDATE SET a.Call_Duration = b.Call_Duration, a.Call_Time = b.Call_Time\n",
    "WHEN NOT MATCHED THEN INSERT (Call_ID, Caller_ID, Recipient_ID, Call_Duration, Call_Time) VALUES (b.Call_ID, b.Caller_ID, b.Recipient_ID, b.Call_Duration, b.Call_Time);\n",
    "\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879d7cd",
   "metadata": {},
   "source": [
    "### Step 5: Copy Into for Incremental Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copy into the sales table for incremental loading\n",
    "spark.sql(\"\"\"\n",
    "COPY INTO telecom.call_logs\n",
    "FROM '/mnt/data/telecom_call_logs_incremental.csv'\n",
    "FILEFORMAT = CSV\n",
    "\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c886d14",
   "metadata": {},
   "source": [
    "### Step 6: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ac2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cleanup: Drop the schema and all tables within it\n",
    "spark.sql(\"\"\"DROP SCHEMA telecom CASCADE;\"\"\")\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
